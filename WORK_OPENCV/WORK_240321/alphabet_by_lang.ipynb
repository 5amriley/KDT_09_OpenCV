{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "2024/03/21 과제\n",
    "알파벳을 사용하는 언어들 각각은, 문장에서 각 문장이 차지하는 패턴이 다를 것이다.\n",
    "특정 문장을 입력했을 때 이 문장의 언어가 무엇일지 맞추는 모델을 만들자."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94dd03208adafedd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "(1) 데이터 전처리"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7c07912a4495fb3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def certain_type_in_dir(my_folder, extension):\n",
    "    # 원하는 확장자의 파일 경로만을 모아서 리스트로 반환하는 함수\n",
    "    # data_type 예시 : csv, jpg, png, txt, ...\n",
    "    if not my_folder.endswith('/'):\n",
    "        my_folder += '/'\n",
    "    if not extension.startswith('.'):\n",
    "        extension = '.' + extension\n",
    "    \n",
    "    filelist = []\n",
    "    datalist = os.listdir(my_folder)\n",
    "    for data_name in datalist:\n",
    "        if os.path.isdir(my_folder + data_name):\n",
    "            filelist.extend(certain_type_in_dir(my_folder + data_name + '/', extension))\n",
    "        else:\n",
    "            # if os.path.splitext(data_name)[-1] == (data_type):\n",
    "            #     print(data_name)\n",
    "            if data_name.endswith(extension):\n",
    "                filelist.append(my_folder + data_name)\n",
    "    return filelist"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:24:59.081703400Z",
     "start_time": "2024-03-21T16:24:59.059181900Z"
    }
   },
   "id": "d66e6102cd1e21f7",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['./train/en-1.txt',\n './train/en-10.txt',\n './train/en-2.txt',\n './train/en-3.txt',\n './train/en-4.txt',\n './train/en-5.txt',\n './train/en-6.txt',\n './train/en-7.txt',\n './train/en-8.txt',\n './train/en-9.txt',\n './train/fr-1.txt',\n './train/fr-10.txt',\n './train/fr-2.txt',\n './train/fr-3.txt',\n './train/fr-4.txt',\n './train/fr-5.txt',\n './train/fr-6.txt',\n './train/fr-7.txt',\n './train/fr-8.txt',\n './train/fr-9.txt',\n './train/id-11.txt',\n './train/id-12.txt',\n './train/id-13.txt',\n './train/id-14.txt',\n './train/id-15.txt',\n './train/id-16.txt',\n './train/id-17.txt',\n './train/id-18.txt',\n './train/id-19.txt',\n './train/id-20.txt',\n './train/tl-11.txt',\n './train/tl-12.txt',\n './train/tl-13.txt',\n './train/tl-14.txt',\n './train/tl-15.txt',\n './train/tl-16.txt',\n './train/tl-17.txt',\n './train/tl-18.txt',\n './train/tl-19.txt',\n './train/tl-20.txt']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "certain_type_in_dir('./train', 'txt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:24:59.110041100Z",
     "start_time": "2024-03-21T16:24:59.077306500Z"
    }
   },
   "id": "1542bc9cea8c52fb",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello, World', 'How are you', \"I'm fine\", 'Thanks']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def split_string_by_punctuation(text):\n",
    "    # 온점, 느낌표, 물음표를 기준으로 문자열 분리\n",
    "    split_text = re.split(r'[.!?]', text)   # 정규 표현식 사용\n",
    "    \n",
    "    # 공백 제거 및 빈 문자열 제거\n",
    "    # 빈 문자열이라면 phrase.strip()이 False\n",
    "    split_text = [phrase.strip() for phrase in split_text if phrase.strip()]\n",
    "    \n",
    "    return split_text\n",
    "\n",
    "# 예시 문자열\n",
    "text = \"Hello, World! How are you? I'm fine. Thanks!\"\n",
    "\n",
    "# 문자열을 온점, 느낌표, 물음표를 기준으로 나누기\n",
    "splitted_text = split_string_by_punctuation(text)\n",
    "print(splitted_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:24:59.110169200Z",
     "start_time": "2024-03-21T16:24:59.094111200Z"
    }
   },
   "id": "47414f8d174850a6",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abc', 'I wanna be good at programming, espacially in AI.', 'There are numerous kinds of people in the world.', ':도 써보고, ;도 써보고, %^&*도 써봤다!', 'What other english sentences are there to test my code?', 'Is there really some kinds of pattern in each languages in terms of how many alphabets are normally used??']\n"
     ]
    }
   ],
   "source": [
    "example_path = './ex/example_txt.txt'\n",
    "\n",
    "example_lines = []\n",
    "with open(example_path, 'r', encoding='utf8') as file:\n",
    "    # 파일의 각 줄을 읽어들임\n",
    "    for line in file:\n",
    "        # 줄 바꿈 문자('\\n')를 제거하여 출력\n",
    "        example_lines.append(line.strip())\n",
    "print(example_lines)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:24:59.161065200Z",
     "start_time": "2024-03-21T16:24:59.109040300Z"
    }
   },
   "id": "aed7391dd8c14aa3",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abc']\n",
      "['I wanna be good at programming, espacially in AI']\n",
      "['There are numerous kinds of people in the world']\n",
      "[':도 써보고, ;도 써보고, %^&*도 써봤다']\n",
      "['What other english sentences are there to test my code']\n",
      "['Is there really some kinds of pattern in each languages in terms of how many alphabets are normally used']\n"
     ]
    }
   ],
   "source": [
    "for line in example_lines:\n",
    "    splitted = split_string_by_punctuation(line)\n",
    "    print(splitted)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:24:59.164595300Z",
     "start_time": "2024-03-21T16:24:59.124130100Z"
    }
   },
   "id": "27316c86ecf984c5",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def read_lines_from_file(file_path):\n",
    "    linelist = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf8') as file:\n",
    "        # 파일의 각 줄을 읽어들임\n",
    "        for line in file:\n",
    "            # 줄 바꿈 문자('\\n')를 제거하여 출력\n",
    "            linelist.append(line.strip())\n",
    "    \n",
    "    return linelist"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:24:59.165661Z",
     "start_time": "2024-03-21T16:24:59.138815300Z"
    }
   },
   "id": "1bb01115c2e9f94f",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['abc',\n 'I wanna be good at programming, espacially in AI.',\n 'There are numerous kinds of people in the world.',\n ':도 써보고, ;도 써보고, %^&*도 써봤다!',\n 'What other english sentences are there to test my code?',\n 'Is there really some kinds of pattern in each languages in terms of how many alphabets are normally used??']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_lines_from_file('./ex/example_txt.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:24:59.200587700Z",
     "start_time": "2024-03-21T16:24:59.152116Z"
    }
   },
   "id": "5c29340d4d0071b",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "en\n",
      "fr\n",
      "fr\n",
      "fr\n",
      "fr\n",
      "fr\n",
      "fr\n",
      "fr\n",
      "fr\n",
      "fr\n",
      "fr\n",
      "id\n",
      "id\n",
      "id\n",
      "id\n",
      "id\n",
      "id\n",
      "id\n",
      "id\n",
      "id\n",
      "id\n",
      "tl\n",
      "tl\n",
      "tl\n",
      "tl\n",
      "tl\n",
      "tl\n",
      "tl\n",
      "tl\n",
      "tl\n",
      "tl\n"
     ]
    }
   ],
   "source": [
    "def get_lang_info(txt_folder):\n",
    "    txt_files_list = certain_type_in_dir(txt_folder, 'txt')\n",
    "    for txt_file in txt_files_list:\n",
    "        start = txt_file.rfind('/')\n",
    "        end = txt_file.rfind('.')\n",
    "        real_name = txt_file[start+1:end]\n",
    "        print(real_name[:2])\n",
    "\n",
    "get_lang_info('./train/')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:24:59.201617500Z",
     "start_time": "2024-03-21T16:24:59.168873500Z"
    }
   },
   "id": "e2013c43b0c63fc7",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'en-8'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_real_name(filename):\n",
    "    \"\"\" 파일의 전체 상대경로에서 경로, 확장자를 제외한 실질적 이름만을 반환하는 함수 \"\"\"\n",
    "    start = filename.rfind('/')\n",
    "    end = filename.rfind('.')\n",
    "    real_name = filename[start+1:end]\n",
    "    return real_name\n",
    "\n",
    "get_real_name('./train/en-8.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:24:59.229936900Z",
     "start_time": "2024-03-21T16:24:59.205907400Z"
    }
   },
   "id": "9f9c2f8f40f01247",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def read_lines_from_folder(txt_folder, MODE=0):\n",
    "    ### 특정 폴더에서 텍스트 파일들만을 골라서 읽어들인 후, \n",
    "    ### 읽어들인 텍스트를 문장 단위로 나눠서 저장하는 함수\n",
    "    \n",
    "    txt_files_list = []     # 텍스트 파일의 경로 리스트\n",
    "    whole_lines = []\n",
    "    lang_info = []     # 각 문장의 언어 정보 [en, fr, id, tl]\n",
    "    \n",
    "    txt_files_list = certain_type_in_dir(txt_folder, 'txt')\n",
    "    # print(txt_files_list)\n",
    "    \n",
    "    if not MODE:    # 일반\n",
    "        for txt_file in txt_files_list:\n",
    "            lines_from_file = read_lines_from_file(txt_file)\n",
    "            lines_from_file = [line for line in lines_from_file if line != '']\n",
    "            whole_lines.extend(lines_from_file)\n",
    "        return whole_lines\n",
    "    else:           # 특별 케이스 (언어 정보까지 저장)\n",
    "        for txt_file in txt_files_list:\n",
    "            lines_from_file = read_lines_from_file(txt_file)\n",
    "            lines_from_file = [line for line in lines_from_file if line != '']\n",
    "            whole_lines.extend(lines_from_file)\n",
    "            lang_info.extend([get_real_name(txt_file)[:2] for _ in range(len(lines_from_file))])\n",
    "        return whole_lines, lang_info"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:24:59.306777500Z",
     "start_time": "2024-03-21T16:24:59.234890200Z"
    }
   },
   "id": "af261a3efb0b914f",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['abc',\n 'I wanna be good at programming, espacially in AI.',\n 'There are numerous kinds of people in the world.',\n ':도 써보고, ;도 써보고, %^&*도 써봤다!',\n 'What other english sentences are there to test my code?',\n 'Is there really some kinds of pattern in each languages in terms of how many alphabets are normally used??']"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_lines_from_folder('./ex/')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:24:59.325157600Z",
     "start_time": "2024-03-21T16:24:59.276361500Z"
    }
   },
   "id": "f69ac786066981c2",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6294 6294\n"
     ]
    }
   ],
   "source": [
    "train_lines, train_langs = read_lines_from_folder('./train/', 1)\n",
    "print(len(train_lines), len(train_langs))   # train 폴더의 총 line 수 (사실, 완전한 sentence는 아님)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:24:59.371720400Z",
     "start_time": "2024-03-21T16:24:59.316389900Z"
    }
   },
   "id": "ff372b1754d4ddb8",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['The main Henry Ford Museum building houses some of the classrooms for the Henry Ford Academy',\n 'Henry Ford Academy is the first charter school in the United States to be developed jointly by a global corporation, public education, and a major nonprofit cultural institution. The school is sponsored by the Ford Motor Company, Wayne County Regional Educational Service Agency and The Henry Ford Museum and admits high school students. It is located in Dearborn, Michigan on the campus of the Henry Ford museum. Enrollment is taken from a lottery in the area and totaled 467 in 2010.[1]',\n 'Freshman meet inside the main museum building in glass walled classrooms, while older students use a converted carousel building and Pullman cars on a siding of the Greenfield Village railroad. Classes are expected to include use of the museum artifacts, a tradition of the original Village Schools. When the Museum was established in 1929, it included a school which served grades kindergarten to college/trade school ages. The last part of the original school closed in 1969.',\n 'The Henry Ford Learning Institute is using the Henry Ford Academy model for further charter schools including the Power House High in Chicago and Alameda School for Art + Design in San Antonio.',\n 'The building received the international annual design award of the Council of Educational Facilities Planners International for 2001, the James D. MacConnell Award for outstanding new educational facilities. Notable attendees include Chris Stroud and Isaac Sudut.']"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lines[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:24:59.374976100Z",
     "start_time": "2024-03-21T16:24:59.338333200Z"
    }
   },
   "id": "9d81312f543df56a",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def count_alphabets(text):\n",
    "    \"\"\" 각 문장에서 모든 문자를 소문자로 바꾼 뒤, \n",
    "    각 알파벳의 등장 횟수를 세는 함수 \"\"\"\n",
    "    filtered = ''.join(c for c in text if c.isalpha())\n",
    "    filtered = filtered.lower()\n",
    "    \n",
    "    alphabet_count = [0 for _ in range(26)]\n",
    "    for alphabet in filtered:\n",
    "        if 97 <= ord(alphabet) <= 122:  # á é í ó ú 같은 문자들 제외하기 위함 (isalpha로 못 걸러냄)\n",
    "            alphabet_count[ord(alphabet)-97] += 1\n",
    "    return alphabet_count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:24:59.376082300Z",
     "start_time": "2024-03-21T16:24:59.357128200Z"
    }
   },
   "id": "fcf8147889d76e8f",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def count_alphabets_debug(idx, text):\n",
    "    \"\"\" count_alphabets 디버그용 \"\"\"\n",
    "    filtered = ''.join(c for c in text if c.isalpha())\n",
    "    filtered = filtered.lower()\n",
    "    \n",
    "    alphabet_count = [0 for _ in range(26)]\n",
    "    for alphabet in filtered:\n",
    "        try:\n",
    "            alphabet_count[ord(alphabet)-97] += 1\n",
    "        except:\n",
    "            print(f'리스트에 저장하던 중 에러 발생. 이 때 문자는 {alphabet} {idx} {ord(alphabet)}')\n",
    "            break\n",
    "    return alphabet_count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:25:30.030910800Z",
     "start_time": "2024-03-21T16:25:30.011107200Z"
    }
   },
   "id": "1a8fdf3db8769305",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[3, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 0, 2, 0, 0, 0, 0]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_alphabets('???? aaavvmreessd')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:24:59.427132Z",
     "start_time": "2024-03-21T16:24:59.399886100Z"
    }
   },
   "id": "d4ae978d4528d889",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[3, 1, 5, 2, 1, 1, 1, 2, 7, 0, 0, 3, 2, 2, 3, 1, 0, 1, 4, 3, 1, 0, 0, 0, 1, 0]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_alphabets(train_lines[6])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:24:59.459945300Z",
     "start_time": "2024-03-21T16:24:59.430408200Z"
    }
   },
   "id": "1a62247582afdb02",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리스트에 저장하던 중 에러 발생. 이 때 문자는 í 383 237\n",
      "리스트에 저장하던 중 에러 발생. 이 때 문자는 í 385 237\n",
      "리스트에 저장하던 중 에러 발생. 이 때 문자는 á 389 225\n",
      "리스트에 저장하던 중 에러 발생. 이 때 문자는 í 391 237\n",
      "리스트에 저장하던 중 에러 발생. 이 때 문자는 ú 392 250\n",
      "리스트에 저장하던 중 에러 발생. 이 때 문자는 í 394 237\n",
      "리스트에 저장하던 중 에러 발생. 이 때 문자는 é 398 233\n",
      "리스트에 저장하던 중 에러 발생. 이 때 문자는 ū 406 363\n",
      "리스트에 저장하던 중 에러 발생. 이 때 문자는 ø 407 248\n",
      "리스트에 저장하던 중 에러 발생. 이 때 문자는 ō 408 333\n",
      "리스트에 저장하던 중 에러 발생. 이 때 문자는 ス 520 12473\n",
      "리스트에 저장하던 중 에러 발생. 이 때 문자는 ä 567 228\n",
      "리스트에 저장하던 중 에러 발생. 이 때 문자는 ב 801 1489\n"
     ]
    }
   ],
   "source": [
    "for idx, line in enumerate(train_lines[:1000]):\n",
    "    count_alphabets_debug(idx, line)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:25:35.707792Z",
     "start_time": "2024-03-21T16:25:35.673939100Z"
    }
   },
   "id": "106ff7bf27bd7ea1",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_feature_list = []\n",
    "\n",
    "for lines in train_lines:\n",
    "    train_feature_list.append(count_alphabets(lines))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:28:13.347074500Z",
     "start_time": "2024-03-21T16:28:13.209464500Z"
    }
   },
   "id": "594a0898c625ac4d",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:28:53.957480600Z",
     "start_time": "2024-03-21T16:28:53.944593800Z"
    }
   },
   "id": "3301266b1675cb9b",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(6294, 26)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_arr = np.array(train_feature_list)\n",
    "train_feature_arr.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:28:54.306528500Z",
     "start_time": "2024-03-21T16:28:54.281749800Z"
    }
   },
   "id": "4d39f7e09a00b34a",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(6294,)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_arr = np.array(train_langs)\n",
    "train_label_arr.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:29:17.547880900Z",
     "start_time": "2024-03-21T16:29:17.518172400Z"
    }
   },
   "id": "823ca27acc4bd181",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6357 6357\n"
     ]
    }
   ],
   "source": [
    "test_lines, test_langs = read_lines_from_folder('./test/', 1)\n",
    "print(len(test_lines), len(test_langs))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:30:41.933464600Z",
     "start_time": "2024-03-21T16:30:41.891857700Z"
    }
   },
   "id": "206562d87775a555",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_feature_list = []\n",
    "\n",
    "for lines in test_lines:\n",
    "    test_feature_list.append(count_alphabets(lines))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:32:16.725494700Z",
     "start_time": "2024-03-21T16:32:16.581825600Z"
    }
   },
   "id": "32213c7759b8715c",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(6357, 26)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature_arr = np.array(test_feature_list)\n",
    "test_feature_arr.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:32:43.589502800Z",
     "start_time": "2024-03-21T16:32:43.552891400Z"
    }
   },
   "id": "7b12293019171ed1",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(6357,)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label_arr = np.array(test_langs)\n",
    "test_label_arr.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:33:03.747882900Z",
     "start_time": "2024-03-21T16:33:03.704943300Z"
    }
   },
   "id": "98a0ed9b0e89736e",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### 문자열 -> 숫자로 인코딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# 문자열 리스트를 숫자로 변환\n",
    "label_encoder.fit(train_langs)\n",
    "train_target_arr = label_encoder.transform(train_langs)\n",
    "test_target_arr = label_encoder.transform(test_langs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:44:23.101922700Z",
     "start_time": "2024-03-21T16:44:23.038267200Z"
    }
   },
   "id": "17404782d1a75e36",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "((6294,), (6357,))"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_arr.shape, test_target_arr.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:44:23.251254900Z",
     "start_time": "2024-03-21T16:44:23.207479100Z"
    }
   },
   "id": "60439acaa2f73636",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array(['en', 'fr', 'id', 'tl'], dtype='<U2')"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_  # 각 숫자가 의미하는 것 (언어)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:40:11.673767400Z",
     "start_time": "2024-03-21T16:40:11.623517600Z"
    }
   },
   "id": "5460e5f91c8488b4",
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "source": [
    "(2) 데이터셋 생성, 데이터로더 생성"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "157070ecceb80e6b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:45:40.554627Z",
     "start_time": "2024-03-21T16:45:40.532416900Z"
    }
   },
   "id": "d4bb935d629c27ca",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## 사용자 정의 Dataset 클래스\n",
    "class LangDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x_data, y_data):\n",
    "        super().__init__()\n",
    "        \n",
    "        # x, y 데이터가 DF라면 ndarray로 바꾸고, ndarray라면 그대로 저장\n",
    "        x_data = x_data.values if isinstance(x_data, pd.DataFrame) else x_data\n",
    "        y_data = y_data.values if isinstance(y_data, pd.DataFrame) else y_data\n",
    "        \n",
    "        # ndarray -> tensor\n",
    "        self.feature = torch.FloatTensor(x_data)    # Float\n",
    "        self.target = torch.LongTensor(y_data)      # Long\n",
    "    \n",
    "    # 데이터셋의 개수 체크 콜백함수\n",
    "    def __len__(self):\n",
    "        return self.target.shape[0]\n",
    "    \n",
    "    # 특정 인덱스 데이터 + 라벨 반환 콜백함수\n",
    "    def __getitem__(self, index):\n",
    "        return self.feature[index], self.target[index]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:45:40.761633300Z",
     "start_time": "2024-03-21T16:45:40.727083300Z"
    }
   },
   "id": "5afe7b10debd2f91",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 학습 데이터셋 생성\n",
    "trainDS = LangDataset(train_feature_arr, train_target_arr)\n",
    "# 테스트 데이터셋 생성\n",
    "testDS = LangDataset(test_feature_arr, test_target_arr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:48:15.781680500Z",
     "start_time": "2024-03-21T16:48:15.740708500Z"
    }
   },
   "id": "da417bdad93ff6cc",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "((tensor([4., 1., 2., 4., 9., 4., 1., 6., 3., 0., 0., 2., 6., 4., 8., 0., 0., 6.,\n          7., 3., 4., 0., 0., 0., 3., 0.]),\n  tensor(0)),\n array([4, 1, 2, 4, 9, 4, 1, 6, 3, 0, 0, 2, 6, 4, 8, 0, 0, 6, 7, 3, 4, 0,\n        0, 0, 3, 0]),\n 0)"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 잘 작동하는지 확인\n",
    "trainDS[0], train_feature_arr[0], train_target_arr[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:48:16.011282200Z",
     "start_time": "2024-03-21T16:48:15.960981Z"
    }
   },
   "id": "ee723fd1fed088a3",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(20, 22)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DataLoader 생성\n",
    "BATCH_SIZE = 300\n",
    "TRAIN_DL = DataLoader(trainDS, batch_size=BATCH_SIZE, drop_last=True, shuffle=True)\n",
    "TEST_DL = DataLoader(testDS, batch_size=BATCH_SIZE)\n",
    "\n",
    "len(TRAIN_DL), len(TEST_DL)     # Epoch 당 반복 단위"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:49:18.731848100Z",
     "start_time": "2024-03-21T16:49:18.701352100Z"
    }
   },
   "id": "75285ea7b31cb21b",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] feature torch.Size([300, 26]) target torch.Size([300])\n",
      "[1] feature torch.Size([300, 26]) target torch.Size([300])\n",
      "[2] feature torch.Size([300, 26]) target torch.Size([300])\n",
      "[3] feature torch.Size([300, 26]) target torch.Size([300])\n",
      "[4] feature torch.Size([300, 26]) target torch.Size([300])\n",
      "[5] feature torch.Size([300, 26]) target torch.Size([300])\n",
      "[6] feature torch.Size([300, 26]) target torch.Size([300])\n",
      "[7] feature torch.Size([300, 26]) target torch.Size([300])\n",
      "[8] feature torch.Size([300, 26]) target torch.Size([300])\n",
      "[9] feature torch.Size([300, 26]) target torch.Size([300])\n",
      "[10] feature torch.Size([300, 26]) target torch.Size([300])\n",
      "[11] feature torch.Size([300, 26]) target torch.Size([300])\n",
      "[12] feature torch.Size([300, 26]) target torch.Size([300])\n",
      "[13] feature torch.Size([300, 26]) target torch.Size([300])\n",
      "[14] feature torch.Size([300, 26]) target torch.Size([300])\n",
      "[15] feature torch.Size([300, 26]) target torch.Size([300])\n",
      "[16] feature torch.Size([300, 26]) target torch.Size([300])\n",
      "[17] feature torch.Size([300, 26]) target torch.Size([300])\n",
      "[18] feature torch.Size([300, 26]) target torch.Size([300])\n",
      "[19] feature torch.Size([300, 26]) target torch.Size([300])\n"
     ]
    }
   ],
   "source": [
    "for _, (feature, target) in enumerate(TRAIN_DL):\n",
    "    print(f'[{_}] feature {feature.shape} target {target.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:49:38.326426500Z",
     "start_time": "2024-03-21T16:49:38.257277200Z"
    }
   },
   "id": "4b5dc6e1ca3a41be",
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "source": [
    "(3) 모델 클래스 정의"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d2d78c22ecd7362"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:50:14.723785600Z",
     "start_time": "2024-03-21T16:50:14.695961600Z"
    }
   },
   "id": "6923e389b23ba81",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### 모델 클래스 정의\n",
    "class LangModel1(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_, out_):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_, 20)\n",
    "        self.layer2 = nn.Linear(20, 20)\n",
    "        self.layer3 = nn.Linear(20, 20)\n",
    "        self.layer4 = nn.Linear(20, out_)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer4(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:53:21.464739200Z",
     "start_time": "2024-03-21T16:53:21.448897700Z"
    }
   },
   "id": "2970ddf470b7e53b",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 실행 디바이스\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 입출력 피쳐\n",
    "IN_DIM, OUT_DIM = train_feature_arr.shape[1], np.unique(train_target_arr).size\n",
    "\n",
    "# 모델 인스턴스\n",
    "MODEL = LangModel1(IN_DIM, OUT_DIM)\n",
    "\n",
    "# 최적화 인스턴스 생성\n",
    "OPTIMIZER = optim.Adam(MODEL.parameters())\n",
    "\n",
    "# 손실 함수\n",
    "LOSS_FN = nn.CrossEntropyLoss().to(DEVICE)  # 다중분류 (4종)\n",
    "\n",
    "# 학습 횟수 설정\n",
    "EPOCHS = 100\n",
    "\n",
    "# 분류 개수\n",
    "CLASSES = len(label_encoder.classes_)   # OUT_DIM"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T17:05:24.356309900Z",
     "start_time": "2024-03-21T17:05:24.308394200Z"
    }
   },
   "id": "c257ff63b984225b",
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(26, 4)"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IN_DIM, OUT_DIM"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T17:05:25.017227800Z",
     "start_time": "2024-03-21T17:05:24.977535400Z"
    }
   },
   "id": "cdf11ce0c23bd7bc",
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('layer1.weight', Parameter containing:\n",
      "tensor([[ 1.9164e-01,  1.0115e-01,  7.0531e-02, -1.8979e-01,  1.4643e-01,\n",
      "         -1.2317e-01,  1.9355e-01,  1.3530e-01,  1.2067e-01,  9.7054e-02,\n",
      "          1.2658e-01,  9.3858e-02, -8.5202e-02,  1.1786e-02,  8.5108e-02,\n",
      "          1.0070e-01,  7.4205e-02,  3.8580e-03,  1.3983e-01, -1.3945e-01,\n",
      "         -2.7925e-02, -1.8213e-01, -4.7501e-02, -6.2318e-03, -1.6986e-01,\n",
      "         -1.9027e-01],\n",
      "        [ 9.0086e-03, -5.4891e-03, -1.3259e-01, -1.0674e-01,  6.6035e-02,\n",
      "         -1.2696e-01,  8.8334e-02,  1.1383e-01, -1.8355e-01,  2.5522e-02,\n",
      "          1.9408e-01, -1.0072e-01,  9.3799e-02,  1.9299e-01, -1.5495e-02,\n",
      "          5.7469e-02, -1.6541e-01,  4.0025e-02, -1.8285e-01,  1.5617e-01,\n",
      "         -4.0157e-02, -1.0641e-01, -1.9796e-02, -7.1064e-02, -7.7451e-02,\n",
      "          9.1876e-02],\n",
      "        [-1.8250e-02,  1.9380e-01,  2.5753e-02, -3.5646e-02,  1.5003e-01,\n",
      "         -2.1004e-02, -7.6116e-02, -9.0725e-02,  1.1691e-01, -1.7737e-02,\n",
      "          9.3226e-02,  1.2441e-01, -8.4072e-02,  7.6470e-02, -1.0501e-01,\n",
      "          1.2048e-01, -7.1913e-02, -1.1761e-01,  6.9122e-02,  3.9514e-02,\n",
      "         -1.5677e-01,  1.3763e-02, -8.7677e-02,  1.1697e-02,  1.3967e-01,\n",
      "          7.0504e-02],\n",
      "        [-5.8750e-02,  1.0146e-01,  1.8264e-01,  1.3645e-01, -1.4529e-01,\n",
      "         -1.4203e-01, -1.5647e-01, -1.8377e-01,  8.7981e-02, -6.3161e-02,\n",
      "         -1.6469e-01, -2.1543e-02,  3.3033e-03, -1.7526e-01,  1.7068e-01,\n",
      "          3.0810e-02, -4.1235e-02, -8.2623e-02,  6.6917e-02,  1.7812e-01,\n",
      "         -1.9493e-01, -9.0264e-02, -5.5059e-02, -1.6948e-01, -1.3506e-01,\n",
      "          2.2666e-02],\n",
      "        [ 1.5725e-01, -1.7183e-01, -3.2007e-02, -1.8387e-02,  1.8389e-01,\n",
      "         -9.6336e-02, -1.3051e-01, -2.4408e-02,  7.8279e-02, -1.1120e-01,\n",
      "         -7.1030e-02,  1.1647e-02,  2.8706e-02, -5.8696e-02, -1.7918e-01,\n",
      "          1.2918e-01, -1.0574e-01,  3.9691e-02,  1.1591e-01,  5.4740e-02,\n",
      "         -6.1604e-02,  7.4601e-03,  8.5183e-02, -9.1934e-02,  1.0253e-01,\n",
      "          1.8319e-01],\n",
      "        [ 3.0052e-02,  9.2693e-02,  6.7726e-02,  1.9934e-02, -1.2511e-01,\n",
      "         -1.1444e-01, -1.5052e-01,  6.5997e-02,  4.4217e-02, -1.8065e-01,\n",
      "          2.5550e-02,  1.7463e-01, -1.8366e-01, -9.9949e-02, -1.1556e-01,\n",
      "         -1.5842e-02,  1.6156e-01,  3.1213e-02, -2.5152e-02,  4.6913e-02,\n",
      "          3.1242e-02, -9.1742e-02,  2.3571e-02, -3.0316e-02,  1.8608e-01,\n",
      "          1.9426e-01],\n",
      "        [-1.6167e-01,  1.9087e-01, -6.0821e-02,  1.8641e-02,  4.1457e-02,\n",
      "          1.6571e-01, -7.7279e-02,  9.1294e-03,  3.0712e-03,  1.4191e-01,\n",
      "          1.5375e-02,  1.9005e-01,  1.2355e-03,  1.6478e-01, -1.9982e-02,\n",
      "         -9.5376e-02, -1.6644e-01, -1.4157e-02, -1.2342e-01, -1.0640e-01,\n",
      "         -1.6970e-01, -6.4011e-02,  1.0501e-01, -3.6013e-03,  1.5519e-01,\n",
      "         -1.5727e-01],\n",
      "        [ 1.1147e-01,  1.7088e-02,  1.1245e-01,  1.2884e-01,  4.5048e-02,\n",
      "         -2.5016e-02, -1.2451e-01, -1.2797e-01, -8.8404e-03, -1.5745e-02,\n",
      "         -7.4757e-02,  1.5916e-01,  1.2102e-01,  1.3207e-01, -1.9072e-01,\n",
      "          1.9363e-01, -1.4027e-01,  1.4285e-01,  7.9368e-02,  1.0017e-01,\n",
      "         -1.6084e-01,  1.4242e-01, -1.5658e-02, -1.3297e-01,  4.7110e-02,\n",
      "          8.9638e-02],\n",
      "        [-1.8642e-01, -4.2609e-02,  1.0693e-01, -1.7753e-01,  2.8127e-04,\n",
      "         -1.7103e-01,  3.5038e-02,  6.7828e-02, -1.7532e-01, -9.7208e-02,\n",
      "         -1.4430e-01, -1.0417e-01,  1.5816e-01,  1.3450e-01,  5.7924e-02,\n",
      "         -6.2151e-02, -3.6585e-02,  7.4686e-02,  9.1710e-02, -7.9010e-02,\n",
      "         -1.8491e-02, -8.4920e-02, -1.6872e-01,  1.6480e-01, -2.1362e-02,\n",
      "         -1.5963e-01],\n",
      "        [-3.4219e-02,  8.3123e-02, -3.4682e-02,  1.6007e-01,  1.4627e-01,\n",
      "         -1.2706e-01,  1.6968e-01, -7.3563e-02,  2.2634e-02,  1.3940e-01,\n",
      "          1.0267e-02,  4.3825e-02, -1.3017e-01,  6.0115e-03, -7.0138e-02,\n",
      "          9.2990e-03,  6.4153e-02, -1.2083e-01,  3.7172e-02, -7.1254e-02,\n",
      "         -1.6519e-01,  1.5817e-01, -1.2941e-01,  3.5300e-02, -5.9015e-02,\n",
      "          3.1322e-03],\n",
      "        [-2.2379e-02, -3.2227e-02, -5.6032e-02,  8.1326e-03, -2.5395e-02,\n",
      "          1.5613e-01, -3.2780e-02, -8.3866e-02,  4.7463e-02, -1.1958e-01,\n",
      "         -1.2599e-01, -7.3626e-02,  7.8810e-02,  1.9022e-01, -1.1574e-01,\n",
      "          1.5631e-01,  3.5911e-02, -1.8296e-01, -3.5733e-02, -1.4808e-01,\n",
      "         -7.6373e-02,  1.4212e-01,  1.2751e-01,  6.5836e-02,  1.8483e-02,\n",
      "          8.3637e-02],\n",
      "        [-1.3217e-02, -1.5799e-01,  7.7226e-02, -4.3686e-02, -3.3027e-02,\n",
      "          6.0892e-02,  7.0000e-02, -1.1131e-01,  1.4207e-02, -1.4043e-02,\n",
      "          9.6833e-02, -1.6149e-02,  1.6402e-03, -4.7899e-02, -3.9011e-02,\n",
      "         -8.1498e-02, -4.5457e-02, -1.0569e-01,  1.3975e-01, -6.4587e-02,\n",
      "          2.8720e-02,  5.4858e-02, -1.6766e-01,  4.6233e-02, -1.3868e-01,\n",
      "          2.7114e-02],\n",
      "        [-1.7624e-01, -7.5155e-02, -1.9073e-01, -2.4649e-02, -1.3982e-01,\n",
      "          9.0562e-02, -2.7704e-02,  1.7743e-01,  1.0253e-01, -2.9239e-02,\n",
      "         -1.5768e-02,  1.3562e-01, -1.5185e-01, -1.6618e-01,  4.9923e-02,\n",
      "          1.0483e-01, -9.3566e-02, -1.9269e-01,  8.6355e-02,  7.8771e-02,\n",
      "         -6.8949e-02, -1.6003e-02,  1.1642e-02,  1.2051e-01,  7.5441e-02,\n",
      "         -1.8586e-01],\n",
      "        [ 1.7062e-01,  1.6596e-01, -1.4111e-01, -2.0228e-02,  1.4496e-01,\n",
      "         -1.2933e-01,  3.0979e-02,  1.2417e-01, -7.6086e-02, -5.9762e-03,\n",
      "         -3.6251e-02, -1.4754e-01, -1.6904e-02, -4.9040e-02, -1.6714e-01,\n",
      "         -1.2960e-01, -2.3723e-05,  7.6363e-02, -1.8214e-02,  1.1776e-01,\n",
      "         -1.0125e-01,  1.2547e-01, -2.7083e-02,  2.3764e-02,  1.2318e-01,\n",
      "         -4.6396e-03],\n",
      "        [-4.8353e-02, -1.8753e-01,  1.4129e-01,  1.3013e-02, -1.7741e-01,\n",
      "          1.4433e-01, -4.3455e-02,  9.5508e-02,  8.9389e-02,  1.1031e-01,\n",
      "         -1.2247e-02,  7.2378e-02, -1.6843e-01, -5.9265e-03, -1.0489e-01,\n",
      "         -7.3921e-02, -1.6275e-01, -8.1017e-02,  5.6884e-02, -1.1190e-01,\n",
      "         -4.8682e-02, -1.4975e-01,  4.6861e-02, -1.9145e-01, -1.0861e-01,\n",
      "         -1.1511e-01],\n",
      "        [-1.0241e-01, -1.5997e-01, -2.8345e-02,  1.7622e-01,  8.2110e-02,\n",
      "         -9.6480e-02, -9.5178e-03, -6.9001e-02, -2.9642e-02,  1.6975e-01,\n",
      "          1.0587e-01, -1.1196e-01, -9.1458e-02,  6.3959e-02, -9.2657e-02,\n",
      "          3.6544e-02,  1.5405e-01, -1.2292e-01,  5.8393e-02,  9.9903e-02,\n",
      "          1.0521e-01, -1.4859e-01, -1.3509e-01,  3.6058e-02,  7.0967e-02,\n",
      "         -6.2190e-02],\n",
      "        [-8.7711e-02,  4.0326e-02,  4.1056e-02, -5.4764e-02, -1.6280e-01,\n",
      "         -7.9909e-03, -1.8637e-01,  5.2547e-02, -5.3684e-02,  1.4743e-01,\n",
      "          1.8166e-02,  1.9500e-01,  1.1520e-01, -5.4673e-02, -8.0505e-02,\n",
      "         -1.2750e-01, -8.9854e-02,  2.1817e-02, -5.2480e-02, -1.2075e-01,\n",
      "         -1.4490e-01,  3.5023e-03,  1.6912e-01, -1.5754e-01,  1.7947e-01,\n",
      "          1.0821e-02],\n",
      "        [ 1.0004e-01, -1.5853e-01,  1.3545e-01,  8.4862e-02,  1.3893e-01,\n",
      "         -1.8900e-01, -2.5318e-03,  1.7026e-02, -9.7390e-03,  7.6820e-02,\n",
      "         -8.0506e-02,  1.8701e-01, -3.5122e-02, -5.3915e-03, -1.6652e-01,\n",
      "         -8.7246e-02, -1.6833e-02,  6.6583e-02,  6.8445e-02,  5.0888e-02,\n",
      "         -2.6088e-02,  1.5291e-01,  7.8864e-02, -1.7106e-01, -3.2867e-03,\n",
      "          1.2827e-01],\n",
      "        [-9.5441e-02, -9.1364e-03, -1.7815e-01,  1.8685e-01, -9.7084e-02,\n",
      "         -1.7327e-01, -4.9449e-03,  1.4621e-01, -1.6523e-01,  8.4690e-03,\n",
      "          1.8801e-01,  1.1480e-01, -1.6377e-01,  2.4184e-02, -1.0107e-01,\n",
      "          1.3313e-01,  1.2572e-01,  6.2723e-02, -1.0575e-01,  1.4290e-01,\n",
      "         -9.7711e-02, -9.2393e-02, -1.4178e-01, -1.4513e-01, -6.3487e-02,\n",
      "         -1.8119e-01],\n",
      "        [-1.6571e-01,  1.7392e-01,  3.1279e-02, -5.5450e-02, -1.2058e-01,\n",
      "         -1.9859e-02,  1.8033e-01, -2.3567e-02,  1.9123e-01,  1.9203e-02,\n",
      "          1.7923e-01,  1.3888e-02, -1.3463e-01, -1.5982e-01, -4.0000e-02,\n",
      "          1.0201e-01, -5.6323e-02, -1.1772e-01, -1.2542e-01, -3.5751e-02,\n",
      "          3.4181e-02,  1.6762e-01,  2.0674e-03, -1.3447e-01, -1.7446e-01,\n",
      "         -6.8062e-02]], requires_grad=True))\n",
      "('layer1.bias', Parameter containing:\n",
      "tensor([-0.1369,  0.0211,  0.0587, -0.1750,  0.0125,  0.1174, -0.0924,  0.1139,\n",
      "         0.0800, -0.0882,  0.1868,  0.0999,  0.1070, -0.1950,  0.1742,  0.0846,\n",
      "         0.0488, -0.0793, -0.1547, -0.1673], requires_grad=True))\n",
      "('layer2.weight', Parameter containing:\n",
      "tensor([[-0.0958, -0.0444, -0.2081,  0.0366,  0.1952, -0.2143,  0.0544,  0.0914,\n",
      "         -0.0961, -0.1326, -0.0426,  0.2042,  0.1394, -0.0374,  0.0037,  0.0284,\n",
      "          0.0738, -0.0760,  0.0541, -0.1813],\n",
      "        [ 0.0518, -0.0672,  0.2087,  0.2004,  0.0564, -0.1696,  0.1702, -0.0434,\n",
      "          0.0397, -0.2158,  0.0807, -0.1487, -0.0135, -0.0108,  0.1596, -0.1731,\n",
      "          0.1920, -0.1389,  0.0900,  0.2060],\n",
      "        [ 0.1041,  0.0468, -0.0868,  0.1783,  0.0883,  0.1951,  0.1221,  0.1577,\n",
      "          0.1832, -0.0237, -0.0373, -0.1338, -0.0598, -0.0758,  0.1328, -0.0834,\n",
      "          0.0284, -0.0657,  0.2200,  0.2145],\n",
      "        [ 0.0828, -0.1558, -0.1408, -0.0663, -0.1858,  0.0715,  0.0310,  0.0246,\n",
      "         -0.2059, -0.1280,  0.2073,  0.0377, -0.1227, -0.1407,  0.0238, -0.2148,\n",
      "          0.0945,  0.0682,  0.1451,  0.1996],\n",
      "        [ 0.1732, -0.0704,  0.1041, -0.0756,  0.0836,  0.0102, -0.1769, -0.1570,\n",
      "         -0.0978,  0.0310, -0.0961, -0.1622, -0.0455, -0.1130, -0.0857,  0.0328,\n",
      "         -0.0916,  0.0854, -0.1612, -0.0328],\n",
      "        [-0.1012,  0.2108, -0.0232, -0.1258,  0.1830,  0.1738, -0.1817,  0.1632,\n",
      "         -0.1863, -0.1442,  0.1447, -0.0521, -0.1689,  0.1086, -0.2087, -0.0872,\n",
      "         -0.0873,  0.0806, -0.2109,  0.0997],\n",
      "        [-0.1829, -0.0218, -0.1877,  0.1316, -0.1490,  0.2137, -0.1973, -0.1594,\n",
      "          0.1138,  0.0569,  0.1705,  0.0359,  0.1212, -0.1526, -0.2163,  0.0299,\n",
      "         -0.2150,  0.1198,  0.0308, -0.0184],\n",
      "        [ 0.0097,  0.0370,  0.0076, -0.0378,  0.1366, -0.1247,  0.1775, -0.0136,\n",
      "          0.1834,  0.1782, -0.1097, -0.0242,  0.1343,  0.1786,  0.2189, -0.2145,\n",
      "          0.0348,  0.0059, -0.1112, -0.1497],\n",
      "        [-0.0485, -0.1690,  0.0099,  0.0742,  0.0865,  0.0040,  0.0168, -0.0995,\n",
      "          0.1253,  0.1275, -0.1074,  0.0986,  0.0783, -0.1974, -0.1392, -0.1451,\n",
      "          0.0107, -0.0076, -0.0291,  0.0268],\n",
      "        [ 0.2214, -0.1604,  0.1272, -0.0260,  0.0822, -0.1194, -0.0055, -0.0865,\n",
      "         -0.0499, -0.0318,  0.0884, -0.1600,  0.0865, -0.1177,  0.2120, -0.2041,\n",
      "         -0.1960,  0.1700,  0.0853, -0.1747],\n",
      "        [-0.0528,  0.0840,  0.0514, -0.0197,  0.0542, -0.1590,  0.1198, -0.0664,\n",
      "          0.0012,  0.0365, -0.0442, -0.2076, -0.1435,  0.1714,  0.1864,  0.2076,\n",
      "         -0.0518, -0.1989,  0.0271, -0.1298],\n",
      "        [ 0.0658,  0.1754,  0.0694,  0.0757,  0.0228, -0.0192, -0.0039, -0.2018,\n",
      "          0.0632, -0.0942,  0.0292, -0.1803,  0.1977,  0.0691, -0.0673, -0.1230,\n",
      "         -0.1285, -0.0826,  0.1213, -0.0226],\n",
      "        [-0.0008, -0.0382, -0.2048,  0.1326,  0.2025,  0.1723, -0.1493, -0.1221,\n",
      "         -0.1474, -0.0812,  0.1835,  0.1605, -0.1870, -0.2037,  0.2086,  0.0885,\n",
      "          0.0952, -0.1697, -0.0476,  0.1180],\n",
      "        [-0.2006, -0.1732,  0.0869, -0.0492,  0.0849, -0.0559, -0.0531,  0.1771,\n",
      "          0.1777, -0.1127,  0.0486,  0.0371, -0.1086,  0.1337, -0.0858,  0.1494,\n",
      "         -0.0365, -0.2225,  0.0337,  0.1604],\n",
      "        [-0.0037, -0.0065, -0.0249, -0.1544, -0.1752,  0.0941,  0.0294,  0.0332,\n",
      "         -0.1216,  0.0882,  0.2103, -0.0009,  0.1578,  0.2037,  0.2152, -0.2085,\n",
      "         -0.1534, -0.1211, -0.1283,  0.1954],\n",
      "        [ 0.0849,  0.0450, -0.0129, -0.2104, -0.0653,  0.0926, -0.1343,  0.0864,\n",
      "          0.0527, -0.0712,  0.2145,  0.1140, -0.1447,  0.2230, -0.0598, -0.0856,\n",
      "          0.0861,  0.1326,  0.0745,  0.1095],\n",
      "        [-0.0788, -0.1463,  0.2067,  0.0369,  0.2209,  0.1395, -0.0671,  0.1323,\n",
      "         -0.2132,  0.1556,  0.0270, -0.1467, -0.1622, -0.2099,  0.0976,  0.0159,\n",
      "          0.1710, -0.1288, -0.1065, -0.0495],\n",
      "        [ 0.1863, -0.1447,  0.0401,  0.2235, -0.0495,  0.0635,  0.0254, -0.0896,\n",
      "          0.0336, -0.1920, -0.0466, -0.1561,  0.0054,  0.0508,  0.2175,  0.1562,\n",
      "          0.1434,  0.0923,  0.1242, -0.1723],\n",
      "        [ 0.0823,  0.0277, -0.1416,  0.1448,  0.0315, -0.0084, -0.0403, -0.1468,\n",
      "          0.0587,  0.1978,  0.2113, -0.1407,  0.0205,  0.0388,  0.2181, -0.1800,\n",
      "          0.0930,  0.0748,  0.1412,  0.0070],\n",
      "        [-0.1941, -0.1092,  0.0818, -0.0492,  0.1205, -0.1086,  0.1113,  0.0717,\n",
      "         -0.0341,  0.0639, -0.0953,  0.0417,  0.1934,  0.1581,  0.0366, -0.0574,\n",
      "         -0.0827, -0.0065, -0.1490, -0.1278]], requires_grad=True))\n",
      "('layer2.bias', Parameter containing:\n",
      "tensor([-0.0273,  0.1438, -0.1956, -0.1620,  0.2170,  0.1532,  0.1427, -0.1931,\n",
      "         0.1915, -0.0082,  0.1407,  0.0060,  0.1805,  0.0232,  0.1645, -0.1031,\n",
      "         0.2142,  0.2051, -0.1044,  0.1908], requires_grad=True))\n",
      "('layer3.weight', Parameter containing:\n",
      "tensor([[-1.9865e-01, -8.2404e-02,  8.8265e-02, -7.1926e-02,  1.1135e-01,\n",
      "         -4.2730e-02,  2.0253e-01, -9.1062e-02, -8.9924e-02, -2.0706e-01,\n",
      "         -2.9294e-02, -7.0656e-02, -1.4620e-02,  1.1157e-01, -2.0720e-01,\n",
      "          5.1432e-03,  1.3114e-01, -1.8854e-01,  1.7527e-02,  1.4122e-01],\n",
      "        [ 2.1937e-01,  1.2318e-01, -1.1613e-01, -2.5382e-02, -7.1856e-02,\n",
      "         -3.5796e-02,  2.1369e-01, -1.0253e-01, -1.9609e-01,  1.5233e-01,\n",
      "          4.0748e-02, -1.0880e-01,  1.0625e-01, -1.5809e-01, -1.5743e-01,\n",
      "         -2.0524e-01, -2.1490e-02, -1.4157e-01, -4.5171e-02, -1.5251e-01],\n",
      "        [-2.1989e-01, -1.3195e-01, -3.5649e-02, -1.6677e-01, -3.9520e-02,\n",
      "          4.3784e-02, -7.0498e-02,  1.8513e-01, -2.5838e-02,  1.2907e-02,\n",
      "          1.8112e-02, -1.4967e-01,  5.3743e-02, -3.5942e-02,  8.7605e-02,\n",
      "         -1.0055e-01, -1.6661e-01,  1.7891e-01, -1.6475e-01, -1.5130e-01],\n",
      "        [-7.8900e-02,  1.1500e-01, -1.1961e-01,  1.0299e-01,  1.1361e-01,\n",
      "          1.1686e-01,  1.7388e-01,  9.6176e-02,  2.0526e-01, -2.1263e-01,\n",
      "          3.8175e-02,  1.2061e-01, -2.1283e-01, -1.5092e-01,  1.9866e-01,\n",
      "         -2.7656e-02, -5.5457e-02, -1.6096e-01,  1.5367e-02,  1.6672e-01],\n",
      "        [-1.4695e-01,  8.4458e-02, -1.1991e-02, -4.2905e-02, -8.6447e-03,\n",
      "         -1.1031e-02,  5.0665e-02, -2.5425e-02, -2.5987e-02, -1.7187e-01,\n",
      "          1.4013e-01, -6.2230e-02,  9.7789e-02, -4.3615e-02, -8.5485e-02,\n",
      "          2.0386e-01, -2.1377e-01,  4.3376e-02, -1.0438e-01,  1.8034e-01],\n",
      "        [ 1.7599e-01,  8.3297e-05,  1.0912e-01,  2.1765e-01,  1.7897e-01,\n",
      "          2.1754e-01,  9.3765e-02,  1.9308e-01, -8.4641e-02,  1.9130e-01,\n",
      "          1.9280e-01,  7.8149e-02, -4.3147e-02,  1.0273e-01,  1.9126e-03,\n",
      "          8.0512e-02,  1.4807e-01, -1.9169e-01,  8.3530e-02, -1.7995e-01],\n",
      "        [-9.7161e-02, -1.7161e-01,  4.2543e-02,  1.7090e-01,  1.6339e-01,\n",
      "          5.6491e-02,  2.0326e-01,  1.5226e-01, -1.1943e-01,  1.7994e-01,\n",
      "         -4.0192e-02, -2.0456e-01,  1.8864e-01,  1.5988e-01, -1.6108e-01,\n",
      "         -2.0022e-01,  2.0045e-01, -6.2997e-02,  6.7336e-02,  5.3013e-02],\n",
      "        [-2.1842e-01, -5.8221e-02, -5.0782e-02, -7.4745e-02,  1.3978e-01,\n",
      "         -1.0819e-01,  2.9889e-02, -1.4298e-01, -4.2376e-02,  1.8450e-01,\n",
      "          3.2382e-02,  2.1017e-01,  2.0403e-01,  4.4099e-02, -1.6547e-01,\n",
      "         -1.2955e-01, -7.6617e-02, -1.6510e-01,  2.1141e-01,  7.5914e-02],\n",
      "        [-2.0287e-01,  2.9676e-02,  7.2186e-02,  6.0734e-02,  1.5709e-01,\n",
      "          3.4334e-02,  1.3916e-01, -2.2254e-01, -1.4550e-01, -7.9405e-02,\n",
      "         -1.3250e-01, -1.5471e-01, -1.2621e-01,  3.0102e-02,  2.0629e-01,\n",
      "          1.1508e-01, -6.5282e-02, -1.7078e-01, -1.4700e-01,  1.9564e-01],\n",
      "        [ 2.0450e-01, -1.3231e-01,  3.9170e-02, -7.6391e-02, -2.1074e-01,\n",
      "         -1.8911e-01, -1.1924e-01, -2.0027e-01, -1.3162e-01,  3.0914e-02,\n",
      "          9.8908e-02, -6.0374e-02,  2.0819e-01,  9.8608e-02, -1.2969e-01,\n",
      "          8.6989e-02, -3.8709e-02, -2.0165e-01, -8.8914e-02,  1.3618e-01],\n",
      "        [ 1.6306e-01, -1.2789e-01,  1.8032e-01, -2.0222e-01,  1.0832e-01,\n",
      "         -1.5007e-01, -3.8992e-02, -1.7833e-01,  9.5340e-02, -4.0832e-02,\n",
      "          1.7459e-01,  1.4854e-01,  6.4122e-02, -1.9744e-01,  1.2253e-01,\n",
      "         -2.0642e-01, -2.1144e-01, -6.8762e-02, -9.0254e-02,  1.3708e-01],\n",
      "        [-9.8558e-02,  2.1351e-02, -2.1791e-01, -6.5368e-04, -1.4985e-01,\n",
      "         -1.0128e-01,  2.2762e-02, -5.3197e-02, -8.1159e-02,  1.3007e-01,\n",
      "          2.0289e-01,  1.0320e-01,  1.1034e-01, -1.5795e-01, -1.2967e-01,\n",
      "          7.0120e-02, -9.0314e-02, -1.5180e-01, -2.7610e-02,  2.0650e-01],\n",
      "        [ 1.2550e-01, -4.6683e-02,  8.6322e-02,  2.0757e-01, -1.5837e-01,\n",
      "         -1.0458e-01, -1.6985e-01,  1.7064e-02, -1.2983e-01,  5.0274e-02,\n",
      "          1.1178e-01,  1.1421e-01,  3.7203e-02,  1.0887e-01, -8.3048e-02,\n",
      "          1.2081e-01, -1.9627e-01,  3.6303e-03,  2.1752e-01,  3.8809e-03],\n",
      "        [ 7.2984e-02, -3.4496e-03,  1.8342e-01, -1.3308e-02,  8.8706e-02,\n",
      "          2.0902e-01, -1.6895e-01,  1.2908e-02, -2.1741e-02, -1.4633e-01,\n",
      "          6.9452e-02,  1.3453e-01,  1.2911e-01,  5.1093e-03,  8.6173e-02,\n",
      "          1.4093e-02,  7.7769e-02,  8.0650e-02, -4.6782e-03, -7.2352e-02],\n",
      "        [-9.0307e-02,  2.0548e-01,  1.9713e-01, -3.4160e-02,  1.4133e-01,\n",
      "          5.7154e-03, -1.5314e-01, -1.4585e-02, -1.4159e-01, -1.0213e-01,\n",
      "          3.2501e-02,  2.2348e-01, -3.1013e-02, -5.7454e-02,  5.0464e-02,\n",
      "         -5.7637e-02, -1.9879e-01, -1.8451e-02, -6.2117e-02, -5.2994e-02],\n",
      "        [-6.2343e-03, -8.8924e-02, -1.4333e-01, -1.6333e-01,  1.9730e-01,\n",
      "         -1.6785e-01,  1.4120e-01,  1.7176e-01, -2.2128e-01, -6.1984e-02,\n",
      "         -1.1892e-01,  3.4081e-02,  5.8074e-02, -1.7442e-01, -3.9198e-02,\n",
      "          4.0445e-02, -6.1712e-02, -1.1857e-01, -1.4486e-02, -9.3801e-03],\n",
      "        [ 9.7682e-02,  3.0674e-02,  5.3203e-02,  1.2835e-01,  9.7636e-02,\n",
      "          2.6251e-02, -1.0737e-01, -1.2984e-01, -4.9019e-03,  2.1540e-01,\n",
      "         -6.8207e-02,  1.3580e-01, -7.4583e-02,  5.5611e-03, -3.1264e-02,\n",
      "         -8.8529e-02, -8.0027e-02, -4.8571e-02,  2.0592e-01,  1.0686e-01],\n",
      "        [ 1.1167e-01,  2.5052e-02, -2.9759e-02, -1.8981e-01, -1.5441e-02,\n",
      "         -1.2931e-01, -5.7672e-02,  2.0690e-01, -1.0823e-01, -4.5789e-02,\n",
      "          1.2170e-01,  2.8251e-02,  5.4170e-03, -7.0352e-02, -1.7095e-01,\n",
      "         -2.0184e-01, -9.0496e-02,  1.1657e-02,  1.8928e-01,  1.0762e-01],\n",
      "        [ 8.6071e-03, -1.6010e-01,  1.7509e-01,  1.1952e-01, -7.8359e-02,\n",
      "          1.0830e-01,  1.4356e-01,  7.5208e-02, -1.4883e-01, -1.0171e-01,\n",
      "          7.2223e-02, -2.0333e-01, -1.1670e-01, -4.8581e-02, -1.3450e-02,\n",
      "         -4.8007e-02,  1.3873e-01, -1.3759e-01, -1.9249e-01, -1.0202e-01],\n",
      "        [-1.7077e-01, -1.9923e-01,  1.2887e-01,  4.9303e-02,  2.0140e-01,\n",
      "         -1.4340e-01,  7.7210e-02,  1.6556e-01,  2.8866e-02,  1.0886e-01,\n",
      "         -2.3185e-02,  5.1844e-02, -1.0048e-02, -2.0623e-01,  5.2127e-02,\n",
      "          9.5261e-02,  5.4981e-03,  1.9794e-01,  1.7554e-01,  1.6962e-01]],\n",
      "       requires_grad=True))\n",
      "('layer3.bias', Parameter containing:\n",
      "tensor([-0.1108,  0.1727,  0.1515,  0.1361, -0.0527, -0.1885, -0.1889,  0.1873,\n",
      "         0.0633, -0.1293,  0.2220,  0.1285,  0.0739, -0.0509,  0.1297, -0.0859,\n",
      "         0.1194,  0.0717,  0.0356, -0.1990], requires_grad=True))\n",
      "('layer4.weight', Parameter containing:\n",
      "tensor([[ 0.0216,  0.0521, -0.0563,  0.0676,  0.1801,  0.0465, -0.1287,  0.0758,\n",
      "         -0.1214, -0.0343, -0.2003,  0.0935, -0.2169, -0.1639, -0.0008, -0.0084,\n",
      "         -0.0200, -0.1480,  0.0491, -0.0248],\n",
      "        [ 0.1386, -0.0770,  0.0095,  0.0831, -0.1850,  0.0884,  0.2129, -0.1922,\n",
      "         -0.1417, -0.0286, -0.0619, -0.0405,  0.0033, -0.0622,  0.0066,  0.2068,\n",
      "          0.0398, -0.0496, -0.1954,  0.1416],\n",
      "        [-0.0389,  0.0563,  0.1644,  0.1084,  0.0633,  0.0316, -0.0263,  0.0108,\n",
      "          0.2041,  0.1809, -0.0199,  0.1508,  0.0231,  0.1977,  0.0087,  0.0955,\n",
      "         -0.2173, -0.1518,  0.0395, -0.1133],\n",
      "        [ 0.0882,  0.1763, -0.0631,  0.1149,  0.1559, -0.1739,  0.2015, -0.1045,\n",
      "          0.0050, -0.1903, -0.2090,  0.0149,  0.0886, -0.2139,  0.0949, -0.0146,\n",
      "          0.2023, -0.0135,  0.0159, -0.1071]], requires_grad=True))\n",
      "('layer4.bias', Parameter containing:\n",
      "tensor([-0.0698,  0.1401,  0.1800,  0.1346], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for para in MODEL.named_parameters():\n",
    "    print(para)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T17:05:25.535945200Z",
     "start_time": "2024-03-21T17:05:25.471448600Z"
    }
   },
   "id": "2e7462e2f33c3ce7",
   "execution_count": 91
  },
  {
   "cell_type": "markdown",
   "source": [
    "(4) 함수 정의"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa860f3448008a0e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torchmetrics.functional as metrics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T17:05:26.467686900Z",
     "start_time": "2024-03-21T17:05:26.450375500Z"
    }
   },
   "id": "2e83c7621bc2ee35",
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### 학습 진행함수\n",
    "def training(device, epoch, model, dataLoader, optimizer, loss_fn, classes):\n",
    "    print(f'model => {id(model)}')\n",
    "    # 학습모드\n",
    "    model.train()\n",
    "\n",
    "    # 배치크기만큼 학습진행 및 저장\n",
    "    train_report = [[], [], []] # loss, acc, f1\n",
    "    for idx, (feature, target) in enumerate(dataLoader):\n",
    "        # 배치크기만큼의 학습 데이터 준비\n",
    "        # 입력된 device로 이동한 텐서 반환(복사본)\n",
    "        feature, target = feature.to(device), target.to(device)\n",
    "\n",
    "        # 배치크기만큼 학습\n",
    "        pre_target = model(feature)\n",
    "        # print(pre_target)\n",
    "\n",
    "        # 손실계산\n",
    "        loss = loss_fn(pre_target, target)\n",
    "        train_report[0].append(loss)\n",
    "\n",
    "        # 성능 평가\n",
    "        acc = metrics.accuracy(pre_target, target, task='multiclass', num_classes=classes)\n",
    "        train_report[1].append(acc)\n",
    "        # print(pre_target.argmax(dim=1)[:10], target[:10], sep='\\n')\n",
    "        \n",
    "        # f1-score\n",
    "        f1 = metrics.f1_score(pre_target, target, task='multiclass', num_classes=classes)\n",
    "        train_report[2].append(f1)\n",
    "\n",
    "        # W, b 업데이트\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if not idx % 50: print('.', end='')\n",
    "\n",
    "    # 에포크 단위 학습 진행 메시지 출력\n",
    "    # 에포크 단위 학습 진행 메시지 출력\n",
    "    loss_score = (sum(train_report[0])/BATCH_SIZE).item()\n",
    "    acc_score = (sum(train_report[1])/BATCH_SIZE).item()\n",
    "    f1_score = (sum(train_report[2])/BATCH_SIZE).item()\n",
    "    print(f'\\n[{epoch+1} Train ] Loss ==> {loss_score:.3f} Acc ==> {acc_score:.3f} F1 ==> {f1_score:.3f}')\n",
    "    \n",
    "    return loss_score, acc_score, f1_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T17:05:27.114823900Z",
     "start_time": "2024-03-21T17:05:27.044689600Z"
    }
   },
   "id": "2263fe2c4973d542",
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model => 2664994433584\n",
      ".\n",
      "[11 Train ] Loss ==> 0.091 Acc ==> 0.027 F1 ==> 0.027\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.09079323709011078, 0.02746666595339775, 0.02746666595339775)"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training(DEVICE, 10, MODEL, TRAIN_DL, OPTIMIZER, LOSS_FN, CLASSES)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T17:05:28.705308900Z",
     "start_time": "2024-03-21T17:05:28.225954100Z"
    }
   },
   "id": "9809cfe88726ab0e",
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### 검증 및 테스트 진행함수\n",
    "def testing(device, epoch, model, dataLoader, loss_fn, classes, kind='valid'):\n",
    "    # 테스트 모드\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 배치크기 만큼의 테스트 데이터 준비\n",
    "        test_report = [[], [], []]\n",
    "        for idx, (feature, target) in enumerate(dataLoader):\n",
    "            # 배치크기만큼의 테스트 데이터 준비\n",
    "            feature, target = feature.to(device), target.to(device)\n",
    "            \n",
    "            # 학습\n",
    "            pre_target = model(feature)\n",
    "            # print('pre_target.shape',pre_target.shape)\n",
    "            # print('target', target.shape)\n",
    "            # print(pre_target)\n",
    "            print(pre_target.argmax(dim=1))\n",
    "            \n",
    "            # 손실계산\n",
    "            loss = loss_fn(pre_target, target)\n",
    "            test_report[0].append(loss)\n",
    "            \n",
    "            # 성능 평가\n",
    "            acc = metrics.accuracy(pre_target, target, task='multiclass', num_classes=classes)\n",
    "            test_report[1].append(acc)\n",
    "            \n",
    "            #f1-score\n",
    "            f1 = metrics.f1_score(pre_target, target, task='multiclass', num_classes=classes)\n",
    "            test_report[2].append(f1)\n",
    "    \n",
    "    testing_type = 'Valid' if kind == 'valid' else 'Test'\n",
    "    \n",
    "    # 에포크 단위 학습 진행 메시지 출력\n",
    "    loss_score = (sum(test_report[0])/BATCH_SIZE).item()\n",
    "    acc_score = (sum(test_report[1])/BATCH_SIZE).item()\n",
    "    f1_score = (sum(test_report[2])/BATCH_SIZE).item() \n",
    "    print(f'[{epoch+1} {testing_type} ] Loss ==> {loss_score:.3f} Acc ==> {acc_score:.3f} F1 ==> {f1_score:.3f}\\n')\n",
    "    \n",
    "    return loss_score, acc_score, f1_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T17:05:36.221989700Z",
     "start_time": "2024-03-21T17:05:36.159787500Z"
    }
   },
   "id": "b8d1736ab2d4ba47",
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        1, 2, 1, 1, 1, 1, 2, 2, 1, 3, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2,\n",
      "        2, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1,\n",
      "        2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2,\n",
      "        2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2,\n",
      "        1, 2, 1, 1, 2, 1, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
      "        0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 3, 2, 1, 2, 2, 2, 0, 2, 2,\n",
      "        1, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2,\n",
      "        0, 2, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1,\n",
      "        2, 0, 2, 3, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 3,\n",
      "        3, 2, 1, 2, 3, 1, 2, 2, 0, 2, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3,\n",
      "        2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2,\n",
      "        2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 3, 1, 1, 2, 2, 2, 2, 2, 2,\n",
      "        1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
      "        2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1])\n",
      "tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2,\n",
      "        2, 1, 0, 2, 1, 3, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 3, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 1, 3, 2, 0, 2, 2, 2, 2, 2, 1, 2, 0, 2, 3, 2, 2, 2, 2, 2, 2,\n",
      "        1, 2, 3, 1, 2, 2, 2, 1, 2, 3, 1, 2])\n",
      "tensor([3, 2, 2, 2, 2, 2, 1, 2, 2, 3, 1, 2, 1, 1, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2,\n",
      "        2, 2, 1, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1,\n",
      "        1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1,\n",
      "        1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
      "        1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1,\n",
      "        1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1,\n",
      "        2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1,\n",
      "        1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2,\n",
      "        1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1,\n",
      "        1, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2,\n",
      "        1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1,\n",
      "        1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 3, 2, 2, 2, 1, 2, 1, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 3, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "        1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2,\n",
      "        1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2,\n",
      "        2, 2, 2, 2, 3, 2, 1, 2, 2, 3, 2, 1, 1, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3,\n",
      "        3, 2, 2, 3, 3, 3, 2, 2, 2, 3, 3, 3])\n",
      "tensor([2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 3, 2, 2, 2, 3, 3, 3, 2, 2, 2, 2,\n",
      "        2, 3, 3, 3, 3, 2, 2, 3, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
      "        1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2])\n",
      "tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 3])\n",
      "[11 Valid ] Loss ==> 0.104 Acc ==> 0.010 F1 ==> 0.010\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.10444526374340057, 0.0100918123498559, 0.0100918123498559)"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing(DEVICE, 10, MODEL, TEST_DL, LOSS_FN, OUT_DIM)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T17:05:37.012072400Z",
     "start_time": "2024-03-21T17:05:36.865140Z"
    }
   },
   "id": "fc2d5b06006fa8fe",
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/100] model => 2664994433584\n",
      ".\n",
      "[1 Train ] Loss ==> 0.084 Acc ==> 0.032 F1 ==> 0.032\n",
      "[Epoch 2/100] model => 2664994433584\n",
      ".\n",
      "[2 Train ] Loss ==> 0.077 Acc ==> 0.035 F1 ==> 0.035\n",
      "[Epoch 3/100] model => 2664994433584\n",
      ".\n",
      "[3 Train ] Loss ==> 0.068 Acc ==> 0.037 F1 ==> 0.037\n",
      "[Epoch 4/100] model => 2664994433584\n",
      ".\n",
      "[4 Train ] Loss ==> 0.061 Acc ==> 0.040 F1 ==> 0.040\n",
      "[Epoch 5/100] model => 2664994433584\n",
      ".\n",
      "[5 Train ] Loss ==> 0.056 Acc ==> 0.043 F1 ==> 0.043\n",
      "[Epoch 6/100] model => 2664994433584\n",
      ".\n",
      "[6 Train ] Loss ==> 0.054 Acc ==> 0.045 F1 ==> 0.045\n",
      "[Epoch 7/100] model => 2664994433584\n",
      ".\n",
      "[7 Train ] Loss ==> 0.052 Acc ==> 0.047 F1 ==> 0.047\n",
      "[Epoch 8/100] model => 2664994433584\n",
      ".\n",
      "[8 Train ] Loss ==> 0.050 Acc ==> 0.047 F1 ==> 0.047\n",
      "[Epoch 9/100] model => 2664994433584\n",
      ".\n",
      "[9 Train ] Loss ==> 0.049 Acc ==> 0.048 F1 ==> 0.048\n",
      "[Epoch 10/100] model => 2664994433584\n",
      ".\n",
      "[10 Train ] Loss ==> 0.048 Acc ==> 0.048 F1 ==> 0.048\n",
      "[Epoch 11/100] model => 2664994433584\n",
      ".\n",
      "[11 Train ] Loss ==> 0.048 Acc ==> 0.048 F1 ==> 0.048\n",
      "[Epoch 12/100] model => 2664994433584\n",
      ".\n",
      "[12 Train ] Loss ==> 0.047 Acc ==> 0.049 F1 ==> 0.049\n",
      "[Epoch 13/100] model => 2664994433584\n",
      ".\n",
      "[13 Train ] Loss ==> 0.046 Acc ==> 0.049 F1 ==> 0.049\n",
      "[Epoch 14/100] model => 2664994433584\n",
      ".\n",
      "[14 Train ] Loss ==> 0.046 Acc ==> 0.049 F1 ==> 0.049\n",
      "[Epoch 15/100] model => 2664994433584\n",
      ".\n",
      "[15 Train ] Loss ==> 0.046 Acc ==> 0.049 F1 ==> 0.049\n",
      "[Epoch 16/100] model => 2664994433584\n",
      ".\n",
      "[16 Train ] Loss ==> 0.045 Acc ==> 0.049 F1 ==> 0.049\n",
      "[Epoch 17/100] model => 2664994433584\n",
      ".\n",
      "[17 Train ] Loss ==> 0.045 Acc ==> 0.049 F1 ==> 0.049\n",
      "[Epoch 18/100] model => 2664994433584\n",
      ".\n",
      "[18 Train ] Loss ==> 0.044 Acc ==> 0.049 F1 ==> 0.049\n",
      "[Epoch 19/100] model => 2664994433584\n",
      ".\n",
      "[19 Train ] Loss ==> 0.044 Acc ==> 0.050 F1 ==> 0.050\n",
      "[Epoch 20/100] model => 2664994433584\n",
      ".\n",
      "[20 Train ] Loss ==> 0.044 Acc ==> 0.050 F1 ==> 0.050\n",
      "[Epoch 21/100] model => 2664994433584\n",
      ".\n",
      "[21 Train ] Loss ==> 0.043 Acc ==> 0.050 F1 ==> 0.050\n",
      "[Epoch 22/100] model => 2664994433584\n",
      ".\n",
      "[22 Train ] Loss ==> 0.043 Acc ==> 0.050 F1 ==> 0.050\n",
      "[Epoch 23/100] model => 2664994433584\n",
      ".\n",
      "[23 Train ] Loss ==> 0.043 Acc ==> 0.050 F1 ==> 0.050\n",
      "[Epoch 24/100] model => 2664994433584\n",
      ".\n",
      "[24 Train ] Loss ==> 0.043 Acc ==> 0.050 F1 ==> 0.050\n",
      "[Epoch 25/100] model => 2664994433584\n",
      ".\n",
      "[25 Train ] Loss ==> 0.043 Acc ==> 0.050 F1 ==> 0.050\n",
      "[Epoch 26/100] model => 2664994433584\n",
      ".\n",
      "[26 Train ] Loss ==> 0.043 Acc ==> 0.050 F1 ==> 0.050\n",
      "[Epoch 27/100] model => 2664994433584\n",
      ".\n",
      "[27 Train ] Loss ==> 0.042 Acc ==> 0.050 F1 ==> 0.050\n",
      "[Epoch 28/100] model => 2664994433584\n",
      ".\n",
      "[28 Train ] Loss ==> 0.042 Acc ==> 0.050 F1 ==> 0.050\n",
      "[Epoch 29/100] model => 2664994433584\n",
      ".\n",
      "[29 Train ] Loss ==> 0.042 Acc ==> 0.050 F1 ==> 0.050\n",
      "[Epoch 30/100] model => 2664994433584\n",
      ".\n",
      "[30 Train ] Loss ==> 0.042 Acc ==> 0.050 F1 ==> 0.050\n",
      "[Epoch 31/100] model => 2664994433584\n",
      ".\n",
      "[31 Train ] Loss ==> 0.042 Acc ==> 0.050 F1 ==> 0.050\n",
      "[Epoch 32/100] model => 2664994433584\n",
      ".\n",
      "[32 Train ] Loss ==> 0.042 Acc ==> 0.050 F1 ==> 0.050\n",
      "[Epoch 33/100] model => 2664994433584\n",
      ".\n",
      "[33 Train ] Loss ==> 0.041 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 34/100] model => 2664994433584\n",
      ".\n",
      "[34 Train ] Loss ==> 0.041 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 35/100] model => 2664994433584\n",
      ".\n",
      "[35 Train ] Loss ==> 0.041 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 36/100] model => 2664994433584\n",
      ".\n",
      "[36 Train ] Loss ==> 0.041 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 37/100] model => 2664994433584\n",
      ".\n",
      "[37 Train ] Loss ==> 0.041 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 38/100] model => 2664994433584\n",
      ".\n",
      "[38 Train ] Loss ==> 0.041 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 39/100] model => 2664994433584\n",
      ".\n",
      "[39 Train ] Loss ==> 0.040 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 40/100] model => 2664994433584\n",
      ".\n",
      "[40 Train ] Loss ==> 0.040 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 41/100] model => 2664994433584\n",
      ".\n",
      "[41 Train ] Loss ==> 0.040 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 42/100] model => 2664994433584\n",
      ".\n",
      "[42 Train ] Loss ==> 0.040 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 43/100] model => 2664994433584\n",
      ".\n",
      "[43 Train ] Loss ==> 0.040 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 44/100] model => 2664994433584\n",
      ".\n",
      "[44 Train ] Loss ==> 0.040 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 45/100] model => 2664994433584\n",
      ".\n",
      "[45 Train ] Loss ==> 0.040 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 46/100] model => 2664994433584\n",
      ".\n",
      "[46 Train ] Loss ==> 0.040 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 47/100] model => 2664994433584\n",
      ".\n",
      "[47 Train ] Loss ==> 0.040 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 48/100] model => 2664994433584\n",
      ".\n",
      "[48 Train ] Loss ==> 0.040 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 49/100] model => 2664994433584\n",
      ".\n",
      "[49 Train ] Loss ==> 0.040 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 50/100] model => 2664994433584\n",
      ".\n",
      "[50 Train ] Loss ==> 0.040 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 51/100] model => 2664994433584\n",
      ".\n",
      "[51 Train ] Loss ==> 0.039 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 52/100] model => 2664994433584\n",
      ".\n",
      "[52 Train ] Loss ==> 0.040 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 53/100] model => 2664994433584\n",
      ".\n",
      "[53 Train ] Loss ==> 0.039 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 54/100] model => 2664994433584\n",
      ".\n",
      "[54 Train ] Loss ==> 0.039 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 55/100] model => 2664994433584\n",
      ".\n",
      "[55 Train ] Loss ==> 0.039 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 56/100] model => 2664994433584\n",
      ".\n",
      "[56 Train ] Loss ==> 0.039 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 57/100] model => 2664994433584\n",
      ".\n",
      "[57 Train ] Loss ==> 0.039 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 58/100] model => 2664994433584\n",
      ".\n",
      "[58 Train ] Loss ==> 0.039 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 59/100] model => 2664994433584\n",
      ".\n",
      "[59 Train ] Loss ==> 0.039 Acc ==> 0.052 F1 ==> 0.052\n",
      "[Epoch 60/100] model => 2664994433584\n",
      ".\n",
      "[60 Train ] Loss ==> 0.039 Acc ==> 0.052 F1 ==> 0.052\n",
      "[Epoch 61/100] model => 2664994433584\n",
      ".\n",
      "[61 Train ] Loss ==> 0.039 Acc ==> 0.052 F1 ==> 0.052\n",
      "[Epoch 62/100] model => 2664994433584\n",
      ".\n",
      "[62 Train ] Loss ==> 0.039 Acc ==> 0.051 F1 ==> 0.051\n",
      "[Epoch 63/100] model => 2664994433584\n",
      ".\n",
      "[63 Train ] Loss ==> 0.038 Acc ==> 0.052 F1 ==> 0.052\n",
      "[Epoch 64/100] model => 2664994433584\n",
      ".\n",
      "[64 Train ] Loss ==> 0.038 Acc ==> 0.052 F1 ==> 0.052\n",
      "[Epoch 65/100] model => 2664994433584\n",
      ".\n",
      "[65 Train ] Loss ==> 0.038 Acc ==> 0.052 F1 ==> 0.052\n",
      "[Epoch 66/100] model => 2664994433584\n",
      ".\n",
      "[66 Train ] Loss ==> 0.038 Acc ==> 0.052 F1 ==> 0.052\n",
      "[Epoch 67/100] model => 2664994433584\n",
      ".\n",
      "[67 Train ] Loss ==> 0.038 Acc ==> 0.052 F1 ==> 0.052\n",
      "[Epoch 68/100] model => 2664994433584\n",
      ".\n",
      "[68 Train ] Loss ==> 0.038 Acc ==> 0.052 F1 ==> 0.052\n",
      "[Epoch 69/100] model => 2664994433584\n",
      ".\n",
      "[69 Train ] Loss ==> 0.039 Acc ==> 0.052 F1 ==> 0.052\n",
      "[Epoch 70/100] model => 2664994433584\n",
      ".\n",
      "[70 Train ] Loss ==> 0.038 Acc ==> 0.052 F1 ==> 0.052\n",
      "[Epoch 71/100] model => 2664994433584\n",
      ".\n",
      "[71 Train ] Loss ==> 0.038 Acc ==> 0.052 F1 ==> 0.052\n",
      "[Epoch 72/100] model => 2664994433584\n",
      ".\n",
      "[72 Train ] Loss ==> 0.038 Acc ==> 0.052 F1 ==> 0.052\n",
      "[Epoch 73/100] model => 2664994433584\n",
      ".\n",
      "[73 Train ] Loss ==> 0.038 Acc ==> 0.052 F1 ==> 0.052\n",
      "[Epoch 74/100] model => 2664994433584\n",
      ".\n",
      "[74 Train ] Loss ==> 0.038 Acc ==> 0.052 F1 ==> 0.052\n",
      "[Epoch 75/100] model => 2664994433584\n",
      ".\n",
      "[75 Train ] Loss ==> 0.038 Acc ==> 0.052 F1 ==> 0.052\n",
      "[Epoch 76/100] model => 2664994433584\n",
      ".\n",
      "[76 Train ] Loss ==> 0.038 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 77/100] model => 2664994433584\n",
      ".\n",
      "[77 Train ] Loss ==> 0.038 Acc ==> 0.052 F1 ==> 0.052\n",
      "[Epoch 78/100] model => 2664994433584\n",
      ".\n",
      "[78 Train ] Loss ==> 0.038 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 79/100] model => 2664994433584\n",
      ".\n",
      "[79 Train ] Loss ==> 0.037 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 80/100] model => 2664994433584\n",
      ".\n",
      "[80 Train ] Loss ==> 0.037 Acc ==> 0.052 F1 ==> 0.052\n",
      "[Epoch 81/100] model => 2664994433584\n",
      ".\n",
      "[81 Train ] Loss ==> 0.037 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 82/100] model => 2664994433584\n",
      ".\n",
      "[82 Train ] Loss ==> 0.037 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 83/100] model => 2664994433584\n",
      ".\n",
      "[83 Train ] Loss ==> 0.037 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 84/100] model => 2664994433584\n",
      ".\n",
      "[84 Train ] Loss ==> 0.037 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 85/100] model => 2664994433584\n",
      ".\n",
      "[85 Train ] Loss ==> 0.037 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 86/100] model => 2664994433584\n",
      ".\n",
      "[86 Train ] Loss ==> 0.037 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 87/100] model => 2664994433584\n",
      ".\n",
      "[87 Train ] Loss ==> 0.037 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 88/100] model => 2664994433584\n",
      ".\n",
      "[88 Train ] Loss ==> 0.037 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 89/100] model => 2664994433584\n",
      ".\n",
      "[89 Train ] Loss ==> 0.037 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 90/100] model => 2664994433584\n",
      ".\n",
      "[90 Train ] Loss ==> 0.037 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 91/100] model => 2664994433584\n",
      ".\n",
      "[91 Train ] Loss ==> 0.037 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 92/100] model => 2664994433584\n",
      ".\n",
      "[92 Train ] Loss ==> 0.037 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 93/100] model => 2664994433584\n",
      ".\n",
      "[93 Train ] Loss ==> 0.037 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 94/100] model => 2664994433584\n",
      ".\n",
      "[94 Train ] Loss ==> 0.037 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 95/100] model => 2664994433584\n",
      ".\n",
      "[95 Train ] Loss ==> 0.037 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 96/100] model => 2664994433584\n",
      ".\n",
      "[96 Train ] Loss ==> 0.036 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 97/100] model => 2664994433584\n",
      ".\n",
      "[97 Train ] Loss ==> 0.036 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 98/100] model => 2664994433584\n",
      ".\n",
      "[98 Train ] Loss ==> 0.037 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 99/100] model => 2664994433584\n",
      ".\n",
      "[99 Train ] Loss ==> 0.036 Acc ==> 0.053 F1 ==> 0.053\n",
      "[Epoch 100/100] model => 2664994433584\n",
      ".\n",
      "[100 Train ] Loss ==> 0.036 Acc ==> 0.053 F1 ==> 0.053\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# 학습 및 검증 데이터별 성능지표값\n",
    "train_ = {'loss':[], 'acc':[], 'f1':[]}\n",
    "val_ = {'loss':[], 'acc':[], 'f1':[]}\n",
    "\n",
    "# 모델 저장 기준 변수\n",
    "pred_va_score = 100\n",
    "\n",
    "# 학습 진행\n",
    "for epo in range(EPOCHS):\n",
    "    print(f'[Epoch {epo+1}/{EPOCHS}]', end=' ')\n",
    "    tr_score = training(DEVICE, epo, MODEL, TRAIN_DL, OPTIMIZER, LOSS_FN, OUT_DIM)\n",
    "    \n",
    "    for idx, key in enumerate(train_):\n",
    "        train_[key].append(tr_score[idx])\n",
    "\n",
    "print('Done!')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T17:06:01.376883600Z",
     "start_time": "2024-03-21T17:05:37.734388700Z"
    }
   },
   "id": "3bdc074e70932f0a",
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Loss와 Acc F1 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import koreanize_matplotlib\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(train_['loss'], label='loss', color='red')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(train_['acc'], label='acc', color='blue')\n",
    "\n",
    "# ax3 = ax1.twinx()\n",
    "# ax3.plot(train_['f1'], label='f1', color='orange')\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "plt.title('train의 loss, acc 비교')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T17:10:04.456265900Z",
     "start_time": "2024-03-21T17:10:04.265441600Z"
    }
   },
   "id": "de8d5138f0f023a0",
   "execution_count": 102
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sklearn으로 모델 학습해보자.\n",
    "좋은 결과의 모델을 만들 수 있음을 확인함"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5f9cf0e982bb09b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c85b9289d0ead3b2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
